{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Code\n",
    "\n",
    "The code below provides a skeleton for the model building & training component of your project. You can add/remove/build on code however you see fit, this is meant as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##Import any other stats/DL/ML packages you may need here. E.g. Keras, scikit-learn, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some early processing of your metadata for easier model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans found: 112120 , Total Headers 112120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95011</th>\n",
       "      <td>00024730_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>24730</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_011/images/00024730_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94395</th>\n",
       "      <td>00024173_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>24173</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2530</td>\n",
       "      <td>2725</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_010/images/00024173_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75586</th>\n",
       "      <td>00018548_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>18548</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_009/images/00018548_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22152</th>\n",
       "      <td>00005872_000.png</td>\n",
       "      <td>Mass</td>\n",
       "      <td>0</td>\n",
       "      <td>5872</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_003/images/00005872_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109413</th>\n",
       "      <td>00029763_012.png</td>\n",
       "      <td>Infiltration</td>\n",
       "      <td>12</td>\n",
       "      <td>29763</td>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_012/images/00029763_012.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83763</th>\n",
       "      <td>00020576_001.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>1</td>\n",
       "      <td>20576</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_009/images/00020576_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59219</th>\n",
       "      <td>00014651_002.png</td>\n",
       "      <td>Atelectasis|Consolidation|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>14651</td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2738</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_007/images/00014651_002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76601</th>\n",
       "      <td>00018829_007.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>7</td>\n",
       "      <td>18829</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_009/images/00018829_007.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31522</th>\n",
       "      <td>00008235_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>8235</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_004/images/00008235_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>00001534_008.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>8</td>\n",
       "      <td>1534</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2662</td>\n",
       "      <td>2577</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/images_002/images/00001534_008.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Index                      Finding Labels  Follow-up #  \\\n",
       "95011   00024730_000.png                          No Finding            0   \n",
       "94395   00024173_000.png                          No Finding            0   \n",
       "75586   00018548_000.png                          No Finding            0   \n",
       "22152   00005872_000.png                                Mass            0   \n",
       "109413  00029763_012.png                        Infiltration           12   \n",
       "83763   00020576_001.png                          No Finding            1   \n",
       "59219   00014651_002.png  Atelectasis|Consolidation|Effusion            2   \n",
       "76601   00018829_007.png                          No Finding            7   \n",
       "31522   00008235_000.png                          No Finding            0   \n",
       "5691    00001534_008.png                          No Finding            8   \n",
       "\n",
       "        Patient ID  Patient Age Patient Gender View Position  \\\n",
       "95011        24730           26              M            PA   \n",
       "94395        24173           31              M            PA   \n",
       "75586        18548           45              M            PA   \n",
       "22152         5872           30              M            PA   \n",
       "109413       29763           33              M            PA   \n",
       "83763        20576           58              M            PA   \n",
       "59219        14651           66              F            PA   \n",
       "76601        18829           55              M            AP   \n",
       "31522         8235           48              F            PA   \n",
       "5691          1534           69              F            PA   \n",
       "\n",
       "        OriginalImage[Width  Height]  OriginalImagePixelSpacing[x        y]  \\\n",
       "95011                  2500     2048                     0.168000  0.168000   \n",
       "94395                  2530     2725                     0.143000  0.143000   \n",
       "75586                  2992     2991                     0.143000  0.143000   \n",
       "22152                  2048     2500                     0.171000  0.171000   \n",
       "109413                 2021     2021                     0.194311  0.194311   \n",
       "83763                  2992     2991                     0.143000  0.143000   \n",
       "59219                  2738     2991                     0.143000  0.143000   \n",
       "76601                  2500     2048                     0.168000  0.168000   \n",
       "31522                  2048     2500                     0.168000  0.168000   \n",
       "5691                   2662     2577                     0.143000  0.143000   \n",
       "\n",
       "        Unnamed: 11                                      path  \n",
       "95011           NaN  /data/images_011/images/00024730_000.png  \n",
       "94395           NaN  /data/images_010/images/00024173_000.png  \n",
       "75586           NaN  /data/images_009/images/00018548_000.png  \n",
       "22152           NaN  /data/images_003/images/00005872_000.png  \n",
       "109413          NaN  /data/images_012/images/00029763_012.png  \n",
       "83763           NaN  /data/images_009/images/00020576_001.png  \n",
       "59219           NaN  /data/images_007/images/00014651_002.png  \n",
       "76601           NaN  /data/images_009/images/00018829_007.png  \n",
       "31522           NaN  /data/images_004/images/00008235_000.png  \n",
       "5691            NaN  /data/images_002/images/00001534_008.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Below is some helper code to read all of your full image filepaths into a dataframe for easier manipulation\n",
    "## Load the NIH data to all_xray_df\n",
    "all_xray_df = pd.read_csv('/data/Data_Entry_2017.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('/data','images*', '*', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "all_xray_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>...</th>\n",
       "      <th>lab_Emphysema</th>\n",
       "      <th>lab_Fibrosis</th>\n",
       "      <th>lab_Hernia</th>\n",
       "      <th>lab_Infiltration</th>\n",
       "      <th>lab_Mass</th>\n",
       "      <th>lab_No Finding</th>\n",
       "      <th>lab_Nodule</th>\n",
       "      <th>lab_Pleural_Thickening</th>\n",
       "      <th>lab_Pneumonia</th>\n",
       "      <th>lab_Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x  ...  lab_Emphysema  lab_Fibrosis lab_Hernia  \\\n",
       "0                        0.143  ...              0             0          0   \n",
       "1                        0.143  ...              1             0          0   \n",
       "2                        0.168  ...              0             0          0   \n",
       "3                        0.171  ...              0             0          0   \n",
       "4                        0.143  ...              0             0          1   \n",
       "\n",
       "   lab_Infiltration  lab_Mass  lab_No Finding  lab_Nodule  \\\n",
       "0                 0         0               0           0   \n",
       "1                 0         0               0           0   \n",
       "2                 0         0               0           0   \n",
       "3                 0         0               1           0   \n",
       "4                 0         0               0           0   \n",
       "\n",
       "   lab_Pleural_Thickening  lab_Pneumonia  lab_Pneumothorax  \n",
       "0                       0              0                 0  \n",
       "1                       0              0                 0  \n",
       "2                       0              0                 0  \n",
       "3                       0              0                 0  \n",
       "4                       0              0                 0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here you may want to create some extra columns in your table with binary indicators of certain diseases \n",
    "## rather than working directly with the 'Finding Labels' column\n",
    "\n",
    "# Todo\n",
    "df_lab = all_xray_df['Finding Labels'].str.get_dummies().add_prefix('lab_')\n",
    "all_xray_df = pd.concat([all_xray_df, df_lab], axis=1)\n",
    "all_xray_df.head()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431\n"
     ]
    }
   ],
   "source": [
    "## Here we can create a new column called 'pneumonia_class' that will allow us to look at \n",
    "## images with or without pneumonia for binary classification\n",
    "all_xray_df.sample(10)\n",
    "# Todo\n",
    "all_xray_df = all_xray_df.rename({'lab_Pneumonia': 'pneumonia_class'}, axis=1)\n",
    "pneumcount = len(all_xray_df[(all_xray_df.pneumonia_class == 1)])\n",
    "print(pneumcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_splits(vargs):\n",
    "    \n",
    "    ## Either build your own or use a built-in library to split your original dataframe into two sets \n",
    "    ## that can be used for training and testing your model\n",
    "    ## It's important to consider here how balanced or imbalanced you want each of those sets to be\n",
    "    ## for the presence of pneumonia \n",
    "    \n",
    "    # Todo\n",
    "    #There are 1431 rows where the pneumonia label is positive. For this reason, we are going to evenly balance it out with a random\n",
    "    #sample of 1431 rows without the pneumonia label to avoid the accuracy paradox without resampling the data.\n",
    "    pneum = vargs[(all_xray_df.pneumonia_class == 1)]\n",
    "    nopneum = vargs[(all_xray_df.pneumonia_class == 0)].head(1431)\n",
    "    concat = pd.concat([pneum, nopneum])\n",
    "    train_data, val_data = train_test_split(concat, test_size=0.2)\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "train, test = create_splits(all_xray_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can begin our model-building & training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First suggestion: perform some image augmentation on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If class_mode=\"binary\", y_col=\"pneumonia_class\" column values must be strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-811e4a854f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtraingen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_train_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mtestgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_test_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-811e4a854f98>\u001b[0m in \u001b[0;36mmake_train_gen\u001b[0;34m(vargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     target_size=(32,32))\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         )\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             validate_filenames=validate_filenames)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# check that inputs match the required class_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# check which image files are valid and keep them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_valid_filepaths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n\u001b[1;32m    188\u001b[0m                                 \u001b[0;34m'values must be strings.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                                 .format(self.class_mode, y_col))\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# check that if binary there are only 2 different classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If class_mode=\"binary\", y_col=\"pneumonia_class\" column values must be strings."
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def my_image_augmentation():\n",
    "    \n",
    "    ## recommendation here to implement a package like Keras' ImageDataGenerator\n",
    "    ## with some of the built-in augmentations \n",
    "    \n",
    "    ## keep an eye out for types of augmentation that are or are not appropriate for medical imaging data\n",
    "    ## Also keep in mind what sort of augmentation is or is not appropriate for testing vs validation data\n",
    "    \n",
    "    ## STAND-OUT SUGGESTION: implement some of your own custom augmentation that's *not*\n",
    "    ## built into something like a Keras package\n",
    "    \n",
    "    # Todo\n",
    "    my_idg = ImageDataGenerator(featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    vertical_flip=False,)\n",
    "    \n",
    "    \n",
    "    return my_idg\n",
    "\n",
    "datagen = my_image_augmentation()\n",
    "\n",
    "def make_train_gen(vargs):\n",
    "    \n",
    "    ## Create the actual generators using the output of my_image_augmentation for your training data\n",
    "    ## Suggestion here to use the flow_from_dataframe library, e.g.:\n",
    "     # Todo\n",
    "    train_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=vargs,\n",
    "    directory=\"./train/\",\n",
    "    x_col=\"path\",\n",
    "    y_col=\"pneumonia_class\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(32,32))\n",
    "    return train_gen\n",
    "\n",
    "\n",
    "def make_val_gen(vargs):\n",
    "    \n",
    "    # Todo\n",
    "    val_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=vargs,\n",
    "    directory=\"./test/\",\n",
    "    x_col=\"path\",\n",
    "    y_col=None,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(32,32))\n",
    "    return val_gen\n",
    "\n",
    "traingen = make_train_gen(train)\n",
    "testgen = make_test_gen(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## May want to pull a single large batch of random validation data for testing after each epoch:\n",
    "valX, valY = val_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## May want to look at some examples of our augmented training data. \n",
    "## This is helpful for understanding the extent to which data is being manipulated prior to training, \n",
    "## and can be compared with how the raw data look prior to augmentation\n",
    "\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    if c_y == 1: \n",
    "        c_ax.set_title('Pneumonia')\n",
    "    else:\n",
    "        c_ax.set_title('No Pneumonia')\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your model: \n",
    "\n",
    "Recommendation here to use a pre-trained network downloaded from Keras for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(vargs):\n",
    "    \n",
    "    # model = VGG16(include_top=True, weights='imagenet')\n",
    "    # transfer_layer = model.get_layer(lay_of_interest)\n",
    "    # vgg_model = Model(inputs = model.input, outputs = transfer_layer.output)\n",
    "    \n",
    "    # Todo\n",
    "    \n",
    "    return vgg_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_my_model(vargs):\n",
    "    \n",
    "    # my_model = Sequential()\n",
    "    # ....add your pre-trained model, and then whatever additional layers you think you might\n",
    "    # want for fine-tuning (Flatteen, Dense, Dropout, etc.)\n",
    "    \n",
    "    # if you want to compile your model within this function, consider which layers of your pre-trained model, \n",
    "    # you want to freeze before you compile \n",
    "    \n",
    "    # also make sure you set your optimizer, loss function, and metrics to monitor\n",
    "    \n",
    "    # Todo\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "\n",
    "\n",
    "## STAND-OUT Suggestion: choose another output layer besides just the last classification layer of your modele\n",
    "## to output class activation maps to aid in clinical interpretation of your model's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below is some helper code that will allow you to add checkpoints to your model,\n",
    "## This will save the 'best' version of your model by comparing it to previous epochs of training\n",
    "\n",
    "## Note that you need to choose which metric to monitor for your model's 'best' performance if using this code. \n",
    "## The 'patience' parameter is set to 10, meaning that your model will train for ten epochs without seeing\n",
    "## improvement before quitting\n",
    "\n",
    "# Todo\n",
    "\n",
    "# weight_path=\"{}_my_model.best.hdf5\".format('xray_class')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(weight_path, \n",
    "#                              monitor= CHOOSE_METRIC_TO_MONITOR_FOR_PERFORMANCE, \n",
    "#                              verbose=1, \n",
    "#                              save_best_only=True, \n",
    "#                              mode= CHOOSE_MIN_OR_MAX_FOR_YOUR_METRIC, \n",
    "#                              save_weights_only = True)\n",
    "\n",
    "# early = EarlyStopping(monitor= SAME_AS_METRIC_CHOSEN_ABOVE, \n",
    "#                       mode= CHOOSE_MIN_OR_MAX_FOR_YOUR_METRIC, \n",
    "#                       patience=10)\n",
    "\n",
    "# callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train your model\n",
    "\n",
    "# Todo\n",
    "\n",
    "# history = my_model.fit_generator(train_gen, \n",
    "#                           validation_data = (valX, valY), \n",
    "#                           epochs = , \n",
    "#                           callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After training for some time, look at the performance of your model by plotting some performance statistics:\n",
    "\n",
    "Note, these figures will come in handy for your FDA documentation later in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After training, make some predictions to assess your model's overall performance\n",
    "## Note that detecting pneumonia is hard even for trained expert radiologists, \n",
    "## so there is no need to make the model perfect.\n",
    "my_model.load_weights(weight_path)\n",
    "pred_Y = new_model.predict(valX, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(t_y, p_y):\n",
    "    \n",
    "    ## Hint: can use scikit-learn's built in functions here like roc_curve\n",
    "    \n",
    "    # Todo\n",
    "    \n",
    "    return\n",
    "\n",
    "## what other performance statistics do you want to include here besides AUC? \n",
    "\n",
    "\n",
    "# def ... \n",
    "# Todo\n",
    "\n",
    "# def ...\n",
    "# Todo\n",
    "    \n",
    "#Also consider plotting the history of your model training:\n",
    "\n",
    "def plot_history(history):\n",
    "    \n",
    "    # Todo\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot figures\n",
    "\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you feel you are done training, you'll need to decide the proper classification threshold that optimizes your model's performance for a given metric (e.g. accuracy, F1, precision, etc.  You decide) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the threshold that optimize your model's performance,\n",
    "## and use that threshold to make binary classification. Make sure you take all your metrics into consideration.\n",
    "\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at some examples of true vs. predicted with our best model: \n",
    "\n",
    "# Todo\n",
    "\n",
    "# fig, m_axs = plt.subplots(10, 10, figsize = (16, 16))\n",
    "# i = 0\n",
    "# for (c_x, c_y, c_ax) in zip(valX[0:100], testY[0:100], m_axs.flatten()):\n",
    "#     c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "#     if c_y == 1: \n",
    "#         if pred_Y[i] > YOUR_THRESHOLD:\n",
    "#             c_ax.set_title('1, 1')\n",
    "#         else:\n",
    "#             c_ax.set_title('1, 0')\n",
    "#     else:\n",
    "#         if pred_Y[i] > YOUR_THRESHOLD: \n",
    "#             c_ax.set_title('0, 1')\n",
    "#         else:\n",
    "#             c_ax.set_title('0, 0')\n",
    "#     c_ax.axis('off')\n",
    "#     i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just save model architecture to a .json:\n",
    "\n",
    "model_json = my_model.to_json()\n",
    "with open(\"my_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
